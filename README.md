# Real-Time Emotion Detection with CNN, OpenCV, and Tkinter

This project performs **real-time facial emotion detection** using a custom-trained **Convolutional Neural Network (CNN)** on grayscale facial images. It uses **OpenCV** for webcam-based face detection, **TensorFlow/Keras** for deep learning, and **Tkinter** for a GUI interface to control and visualize results.

## ğŸ“Œ Features

- Train a CNN model on your own facial emotion dataset
- Real-time emotion detection from webcam feed
- Logs detected emotions (with timestamp and position) into a JSON file
- Interactive GUI with buttons to stop detection and view emotion distribution
- Emotion categories: `Angry`, `Disgust`, `Fear`, `Happy`, `Sad`, `Surprise`, `Neutral`

---

## ğŸ§  Dataset Format

The dataset directory (`data/`) should be structured as follows:
Used data: [https://www.kaggle.com/datasets/ananthu017/emotion-detection-fer]

```
data/
â”œâ”€â”€ 0 Â # Angry
â”œâ”€â”€ 1 Â # Disgust
â”œâ”€â”€ 2 Â # Fear
â”œâ”€â”€ 3 Â # Happy
â”œâ”€â”€ 4 Â # Sad
â”œâ”€â”€ 5 Â # Surprise
â””â”€â”€ 6 Â # Neutral
```

Each folder should contain grayscale `.jpg` or `.png` face images sized 48x48 or will be resized accordingly.

---

## ğŸ§ª Model Architecture

- 3 convolutional blocks with `Conv2D`, `MaxPooling2D`, and `Dropout`
- Fully connected layer followed by `BatchNormalization` and `Dropout`
- Output layer with `softmax` activation for 7 emotion classes

---

## ğŸ› ï¸ Requirements

Install dependencies using:

```bash
pip install tensorflow numpy opencv-python matplotlib
```

Optional (for GUI):

```bash
pip install tk
```

---

## ğŸš€ How to Run

### 1. **Train the Model**

Make sure the dataset is in the correct format. The script automatically:

- Loads and preprocesses images
- Trains the model with data augmentation
- Saves the model to `custom_fer_model.h5`

```python
# Just run the script and model will be trained
```

### 2. **Start Real-Time Detection**

The GUI will launch with:

- A **Stop and Save** button to terminate camera and log data
- A **Plot Emotion Distribution** button to visualize the frequency of each emotion

Emotions detected will be saved in a file named: `emotion_log.json`.

---

## ğŸ“Š Sample JSON Log Format

```json
{
Â  "timestamp": "2025-04-06 13:45:22",
Â  "emotion": "Happy",
Â  "confidence": "96.23%",
Â  "position": {
Â  Â  "x": 123,
Â  Â  "y": 88,
Â  Â  "width": 64,
Â  Â  "height": 64
Â  }
}
```

---

## ğŸ–¼ï¸ Emotion Distribution Graph

After running detection, you can click **"Plot Emotion Distribution"** to see a bar chart summarizing all detected emotions.

---

## ğŸ’¡ Notes

- Ensure a good light environment for better face detection.
- Use a dataset with a balanced number of images per class for better accuracy.
- Press `q` during camera view to manually stop detection.

---

## ğŸ“Œ Future Enhancements

- Integrate audio-based emotion detection
- Provide video input instead of just webcam
- Add option to export data to Excel or Google Sheets
- Create a mobile/desktop application interface

---

## ğŸ™Œ Credits

Developed by **Ahana**  
Project for **Emotion Detection** coursework at Bennett University  
Using: TensorFlow, OpenCV, Tkinter, Matplotlib

---
